---
layout: post
title: Blog Post 5
---

## <font color = grey>Purpose
---
In this blog post, we will study several new techniques related to image classification and transfer learning in Tensorflow. In particular, we will explore different models to differetiate between pictures of dogs and pictures and cats. Additional resources can be found on the Tensorflow [Transfer Learning Tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning).
<br><br>

## <font color = grey>Method
--- 
#### Step I. Load Packages and Obtain Data
As always, we need to import the necessary packages before everything. 


```python
import os
import tensorflow as tf
from tensorflow.keras import utils 
```

For this activity, we will use a sample dataset provided by TensorFlow that contains the images of cats and dogs. And run our models on this dataset. Refer to the following code block to extract the data and the spliting between training dataset and validation dataset. 

Note here we employed `image_dataset_from_directory` to construct a `dataset`. The first argument specifies where the images are located; the `shuffle` argument tells us that the order will be randomized when extracting data from this directory; `batch_size` determines the no. of data points gathered from the directory at once (*In our case, we will get 32 images from each of the datasets*); `image_size` specifies the size of the input images.


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

    Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
    68608000/68606236 [==============================] - 1s 0us/step
    68616192/68606236 [==============================] - 1s 0us/step
    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.


The following code block is related to rapidly reading data:


```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

We first want to create a function `dog_and_cat` to visualize some random images. In this figure, the first row shows three random pictures of cats and the second row shows three random pictures of dogs. Note that by experimenting with the dataset, we know that label `0` corresponds to `"cat"` while label `1` corresponds to `"dog"`. A labeled plot is demonstrated as follows:


```python
# import the package
import matplotlib.pyplot as plt

# create label names
class_names = ['cat', 'dog']

def dog_and_cat():
  # specify figure size 
  plt.figure(figsize=(10,5))

  # retreive images and labels
  for images, labels in train_dataset.take(1):
    no_cat = 0
    no_dog = 0

    # write a for loop to add images
    for i in range(32):
      # break the loop if all 6 pictures are added
      if no_cat > 3 and no_dog > 3:
        break
      # plot cats
      if class_names[labels[i]] == 'cat':
        no_cat += 1
        if no_cat > 3:
          continue
        else: 
          # starting from the first row
          ax = plt.subplot(2, 3, no_cat)
          plt.imshow(images[i].numpy().astype("uint8"))
          plt.title(class_names[labels[i]])
          plt.axis("off")
      # plot dogs
      else:
        no_dog += 1
        if no_dog > 3:
          continue
        else: 
          # starting from the second row
          ax = plt.subplot(2, 3, no_dog+3)
          plt.imshow(images[i].numpy().astype("uint8"))
          plt.title(class_names[labels[i]])
          plt.axis("off")
```

Visualize the result by calling the function:


```python
dog_and_cat()
```


![Blog_Post_5_9_0.png](/images/Blog_Post_5_9_0.png)
    


Run the following line to create an iterator called `labels_iterator`: 


```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
labels_iterator
```




    <tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x7f2210453610>



Then we can iterate to see the label frequencies:


```python
no_cat = 0
no_dog = 0
for labels in labels_iterator:
  if labels == 0:
     no_cat += 1
  else:
     no_dog += 1

print("There are " + str(no_cat) + " cat images.")
print("There are " + str(no_dog) + " dog images.")
```

    There are 1000 cat images.
    There are 1000 dog images.


So we should have the following benchmark before constructing our model:
> **The label frequencies for cat images and dog images are 1000 respectively. Hence, by random guessing, the probability of correctly guessing the label is 50%. Therefore, in order to provide meaningful data science work, our models have to achieve accuracy higher than 50%.**

<br>

#### Step II. First Model
For our first model, we will simply create a model using some of the layers we discussed in class. In particular, our `model1` will have 3 `Conv2D` layers, 2 `MaxPooling2D` layers, 1 `Flatten` layer, 2 `Dense` layers, and 1`Dropout` layer.


```python
# import the packages
from tensorflow.keras import datasets, layers, models

# build the model
model1 = models.Sequential([
    layers.Conv2D(20, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(20, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(20, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dropout(0.05),
    layers.Dense(40, activation='relu'),
    layers.Dense(2) # number of classes
])

# model summary
model1.summary()
```

    Model: "sequential"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     conv2d (Conv2D)             (None, 158, 158, 20)      560       
                                                                     
     max_pooling2d (MaxPooling2D  (None, 79, 79, 20)       0         
     )                                                               
                                                                     
     conv2d_1 (Conv2D)           (None, 77, 77, 20)        3620      
                                                                     
     max_pooling2d_1 (MaxPooling  (None, 38, 38, 20)       0         
     2D)                                                             
                                                                     
     conv2d_2 (Conv2D)           (None, 36, 36, 20)        3620      
                                                                     
     flatten (Flatten)           (None, 25920)             0         
                                                                     
     dropout (Dropout)           (None, 25920)             0         
                                                                     
     dense (Dense)               (None, 40)                1036840   
                                                                     
     dense_1 (Dense)             (None, 2)                 82        
                                                                     
    =================================================================
    Total params: 1,044,722
    Trainable params: 1,044,722
    Non-trainable params: 0
    _________________________________________________________________


Time to train the model to see the validation accuracy. We will train the model for 20 epochs:


```python
# specify loss function
model1.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# train the model
history1 = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 9s 127ms/step - loss: 13.6035 - accuracy: 0.5300 - val_loss: 0.6901 - val_accuracy: 0.5396
    Epoch 2/20
    63/63 [==============================] - 9s 130ms/step - loss: 0.6400 - accuracy: 0.6195 - val_loss: 0.6826 - val_accuracy: 0.5953
    Epoch 3/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.5488 - accuracy: 0.7280 - val_loss: 0.6855 - val_accuracy: 0.6312
    Epoch 4/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.4508 - accuracy: 0.7970 - val_loss: 0.6813 - val_accuracy: 0.6374
    Epoch 5/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.3575 - accuracy: 0.8610 - val_loss: 0.7006 - val_accuracy: 0.6436
    Epoch 6/20
    63/63 [==============================] - 5s 70ms/step - loss: 0.2537 - accuracy: 0.9095 - val_loss: 0.9150 - val_accuracy: 0.6052
    Epoch 7/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.1701 - accuracy: 0.9495 - val_loss: 0.9697 - val_accuracy: 0.6275
    Epoch 8/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.1151 - accuracy: 0.9680 - val_loss: 1.1153 - val_accuracy: 0.6250
    Epoch 9/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.0856 - accuracy: 0.9750 - val_loss: 1.1247 - val_accuracy: 0.6188
    Epoch 10/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.0509 - accuracy: 0.9905 - val_loss: 1.6187 - val_accuracy: 0.5978
    Epoch 11/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.0659 - accuracy: 0.9790 - val_loss: 1.5191 - val_accuracy: 0.6052
    Epoch 12/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.0297 - accuracy: 0.9970 - val_loss: 1.7523 - val_accuracy: 0.6027
    Epoch 13/20
    63/63 [==============================] - 5s 70ms/step - loss: 0.0247 - accuracy: 0.9965 - val_loss: 1.6306 - val_accuracy: 0.6139
    Epoch 14/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.0140 - accuracy: 0.9985 - val_loss: 1.7081 - val_accuracy: 0.6064
    Epoch 15/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.0095 - accuracy: 0.9990 - val_loss: 1.9289 - val_accuracy: 0.6101
    Epoch 16/20
    63/63 [==============================] - 5s 71ms/step - loss: 0.0093 - accuracy: 0.9990 - val_loss: 1.8893 - val_accuracy: 0.6250
    Epoch 17/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 1.9859 - val_accuracy: 0.6139
    Epoch 18/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 2.1587 - val_accuracy: 0.6139
    Epoch 19/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 2.0940 - val_accuracy: 0.6114
    Epoch 20/20
    63/63 [==============================] - 5s 72ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 2.2048 - val_accuracy: 0.6176


plot the training accuracy and validation accuracy as follows:


```python
plt.plot(history1.history["accuracy"], label = "training")
plt.plot(history1.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")

plt.legend()
```




    <matplotlib.legend.Legend at 0x7f2210413890>




![Blog_Post_5_19_1.png](/images/Blog_Post_5_19_1.png)
    


A few observations here:
> **My validation accuracy fluctuates around 60%, which stabilizes between 55% and 65% during training.** This is better than the baseline 50% from Step I of our activity. However, overfitting can be observed in model 1 as training accuracy gets close to 100% in the end, which is significantly higher than the validation accuracy.

<br>

#### Step III. Model with Data Augmentation
In our second model, we are going to add some data augmentation layers to my model. Data augmentation is the practice of including modified copies, such as fliping and rotating, of the same images in the training set, based on the assumption that such modification will not change the label because a cat image is still a cat image after rotating 90 degrees. 

We will first explore how to create the layers to flip and rotate the images.
First, the `tf.keras.layers.RandomFlip()` layer will help randomly flip the images:


```python
# select an image
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  image = tf.expand_dims(first_image, 0)

# create a layer to allow random horizontal and vertical flips
rdm_flip = tf.keras.layers.RandomFlip(
    mode="horizontal_and_vertical"
)

# draw 9 pictures to demonstrate the flipping
for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  augmented_image = rdm_flip(image)
  # original image
  if i == 0:
    plt.imshow(image[0]/255)
  # random flips
  else:
    plt.imshow(augmented_image[0]/255)
  plt.axis('off')
```


![Blog_Post_5_21_0.png](/images/Blog_Post_5_21_0.png)
    


Second, the `tf.keras.layers.RandomRotation()` layer will help randomly rotate the images:


```python
plt.figure(figsize=(10, 10))

# create a layer to allow random rotation by 2*pi*0.5
rdm_rot = tf.keras.layers.RandomRotation(
  0.5
)

# draw 9 pictures to demonstrate the rotation
for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  augmented_image = rdm_rot(image)
  # original image
  if i == 0:
    plt.imshow(image[0]/255)
  # random flips
  else:
    plt.imshow(augmented_image[0]/255)
  plt.axis('off')
```


![Blog_Post_5_23_0.png](/images/Blog_Post_5_23_0.png)
    


Here in model 2, we will incorporate the augmentation layers as the first two layers. 


```python
# construct the model
model2 = models.Sequential([
    layers.RandomFlip('horizontal_and_vertical'),
    layers.RandomRotation(0.5),
    layers.Conv2D(20, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(20, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(20, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(40, activation='relu'),
    layers.Dense(2) # number of classes
])

# specify loss function
model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# train the model
history2 = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 79ms/step - loss: 7.0777 - accuracy: 0.5330 - val_loss: 0.6863 - val_accuracy: 0.5458
    Epoch 2/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6844 - accuracy: 0.5640 - val_loss: 0.6678 - val_accuracy: 0.5879
    Epoch 3/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6727 - accuracy: 0.5805 - val_loss: 0.6682 - val_accuracy: 0.5569
    Epoch 4/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6641 - accuracy: 0.6045 - val_loss: 0.6369 - val_accuracy: 0.6262
    Epoch 5/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.6424 - accuracy: 0.6270 - val_loss: 0.6461 - val_accuracy: 0.6213
    Epoch 6/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.6543 - accuracy: 0.6205 - val_loss: 0.6671 - val_accuracy: 0.5606
    Epoch 7/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.6556 - accuracy: 0.5925 - val_loss: 0.6374 - val_accuracy: 0.6324
    Epoch 8/20
    63/63 [==============================] - 5s 73ms/step - loss: 0.6395 - accuracy: 0.6300 - val_loss: 0.6391 - val_accuracy: 0.6361
    Epoch 9/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6672 - accuracy: 0.5935 - val_loss: 0.7004 - val_accuracy: 0.5928
    Epoch 10/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6698 - accuracy: 0.5925 - val_loss: 0.6577 - val_accuracy: 0.6163
    Epoch 11/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.6923 - accuracy: 0.5840 - val_loss: 0.6650 - val_accuracy: 0.6064
    Epoch 12/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6653 - accuracy: 0.6100 - val_loss: 0.6435 - val_accuracy: 0.6250
    Epoch 13/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6486 - accuracy: 0.6255 - val_loss: 0.6442 - val_accuracy: 0.6312
    Epoch 14/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6436 - accuracy: 0.6315 - val_loss: 0.6428 - val_accuracy: 0.6349
    Epoch 15/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.6392 - accuracy: 0.6220 - val_loss: 0.6345 - val_accuracy: 0.6522
    Epoch 16/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.6358 - accuracy: 0.6250 - val_loss: 0.6352 - val_accuracy: 0.6275
    Epoch 17/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.6297 - accuracy: 0.6400 - val_loss: 0.6207 - val_accuracy: 0.6510
    Epoch 18/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.6247 - accuracy: 0.6490 - val_loss: 0.6233 - val_accuracy: 0.6572
    Epoch 19/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.6160 - accuracy: 0.6530 - val_loss: 0.6140 - val_accuracy: 0.6696
    Epoch 20/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6266 - accuracy: 0.6365 - val_loss: 0.6170 - val_accuracy: 0.6745


plot the training accuracy and validation accuracy as follows:


```python
plt.plot(history2.history["accuracy"], label = "training")
plt.plot(history2.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")

plt.legend()
```




    <matplotlib.legend.Legend at 0x7f1c179ff850>





![Blog_Post_5_27_1.png](/images/Blog_Post_5_27_1.png) 
    


 A few observations here:
> **My validation accuracy starts from around 55% and steadily increases to around 67% in the end of the training. It has delivered validation accuracy consistently higher than 56%.** This result is slightly better than model 1 as model 1 delivers results in between 55% and 65%. Additionally, for model 2, we do not observe overfitting as validation accuracy and training accuracy are very close throughout the training process. 

<br>

#### Step IV. Data Processing
Moreover, it can be useful to "massage" the data before passing to the neural networks. For instance, many models will train faster if RGB values are normalized between 0 and 1, or possibly between -1 and 1. Therefore, we can first create a `preprocessor` layer that will be inserted as the first layer in our model 3 as follows:


```python
# create a layer to normalize data
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```

Now we combine both `preprocessor` layer and data augmentation layers from the last step to build model 3:


```python
# construct the model
model3 = tf.keras.models.Sequential([
  preprocessor,
  layers.RandomFlip('horizontal_and_vertical'),
  layers.RandomRotation(0.5),
  layers.Conv2D(30, (3, 3), activation='relu', input_shape=(160, 160, 3)),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(30, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(60, (3, 3), activation='relu'),
  layers.Flatten(),
  layers.Dense(60, activation='relu'),
  layers.Dense(2) 
])

# specify the loss function
model3.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# train the model
history3 = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 9s 91ms/step - loss: 0.7220 - accuracy: 0.5620 - val_loss: 0.6368 - val_accuracy: 0.6089
    Epoch 2/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.6490 - accuracy: 0.6185 - val_loss: 0.6219 - val_accuracy: 0.6262
    Epoch 3/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6270 - accuracy: 0.6410 - val_loss: 0.6123 - val_accuracy: 0.6374
    Epoch 4/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6102 - accuracy: 0.6560 - val_loss: 0.6279 - val_accuracy: 0.6262
    Epoch 5/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5982 - accuracy: 0.6735 - val_loss: 0.5821 - val_accuracy: 0.6782
    Epoch 6/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.5889 - accuracy: 0.6795 - val_loss: 0.5876 - val_accuracy: 0.6819
    Epoch 7/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5746 - accuracy: 0.7010 - val_loss: 0.6258 - val_accuracy: 0.6807
    Epoch 8/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5716 - accuracy: 0.6960 - val_loss: 0.5722 - val_accuracy: 0.6856
    Epoch 9/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5742 - accuracy: 0.6885 - val_loss: 0.5680 - val_accuracy: 0.6918
    Epoch 10/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.5655 - accuracy: 0.7040 - val_loss: 0.5502 - val_accuracy: 0.7017
    Epoch 11/20
    63/63 [==============================] - 5s 83ms/step - loss: 0.5590 - accuracy: 0.7105 - val_loss: 0.6009 - val_accuracy: 0.6980
    Epoch 12/20
    63/63 [==============================] - 7s 102ms/step - loss: 0.5628 - accuracy: 0.7020 - val_loss: 0.5383 - val_accuracy: 0.7252
    Epoch 13/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.5285 - accuracy: 0.7275 - val_loss: 0.5948 - val_accuracy: 0.7067
    Epoch 14/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.5358 - accuracy: 0.7255 - val_loss: 0.5691 - val_accuracy: 0.6980
    Epoch 15/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.5314 - accuracy: 0.7210 - val_loss: 0.5767 - val_accuracy: 0.7030
    Epoch 16/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5323 - accuracy: 0.7245 - val_loss: 0.5371 - val_accuracy: 0.7265
    Epoch 17/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5177 - accuracy: 0.7350 - val_loss: 0.5728 - val_accuracy: 0.7067
    Epoch 18/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5175 - accuracy: 0.7380 - val_loss: 0.5688 - val_accuracy: 0.7129
    Epoch 19/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.4962 - accuracy: 0.7545 - val_loss: 0.5389 - val_accuracy: 0.7302
    Epoch 20/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.5263 - accuracy: 0.7340 - val_loss: 0.5623 - val_accuracy: 0.7104


plot the training accuracy and validation accuracy as follows:


```python
plt.plot(history3.history["accuracy"], label = "training")
plt.plot(history3.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")

plt.legend()
```




    <matplotlib.legend.Legend at 0x7f1b1f938490>




![Blog_Post_5_33_1.png](/images/Blog_Post_5_33_1.png)   
    


 A few observations here:
> **My validation accuracy becomes stabilized slightly higher than 70% after running 10 epoches.** This accuracy level is clearly better than both model 1 and model 2. Additionally, for model 3, we do not observe overfitting as validation accuracy and training accuracy are very close throughout the training process. 

<br>

#### Step V. Transfer Learning
For many cases, someone might already have trained a model that does similar work, and might already have captured some relevant patterns or relations between the various variables. It is more efficient for us to employ these models and incorporate them into our model analysis. We need to access a pre-existing "base model", and then add it to our model, and then train that model. The following code block help us download the "base model" and save it as `base_model_layer` that we will include in our model later on. 


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5
    9412608/9406464 [==============================] - 0s 0us/step
    9420800/9406464 [==============================] - 0s 0us/step


Great! In our final step, we will incorporate everything we have learned from this bog post - a preprossor layer first, followed by data augmentation layers, and the "base model" from transfer learning, an additional `GlobalMaxPooling2D` layer, and finally, a `Dense` layer to perform the image classification. 


```python
# Construct the final classification model
model4 = tf.keras.models.Sequential([
  preprocessor,
  layers.RandomFlip('horizontal'),
  layers.RandomRotation(0.5),
  base_model_layer,
  layers.GlobalAveragePooling2D(),
  layers.Dense(2) 
])
```

We can take a look at the model summary:


```python
model4.summary()
```

    Model: "sequential_1"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model_1 (Functional)        (None, 160, 160, 3)       0         
                                                                     
     random_flip (RandomFlip)    (None, 160, 160, 3)       0         
                                                                     
     random_rotation (RandomRota  (None, 160, 160, 3)      0         
     tion)                                                           
                                                                     
     model (Functional)          (None, 5, 5, 1280)        2257984   
                                                                     
     global_average_pooling2d (G  (None, 1280)             0         
     lobalAveragePooling2D)                                          
                                                                     
     dense_2 (Dense)             (None, 2)                 2562      
                                                                     
    =================================================================
    Total params: 2,260,546
    Trainable params: 2,562
    Non-trainable params: 2,257,984
    _________________________________________________________________


Observation:
> There are more than 2 million parameters in the `base_model_layer`! It is way higher than the no. of parameters we see in model 1 back in the model summary in step I. However, there are only around 2 thousand trainable params in this model training since we do not need all the params for our task when we use the base model. 

Let us take a look at how the model performs:


```python
# specify the loss function
model4.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# train the model
history4 = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 20s 112ms/step - loss: 0.3450 - accuracy: 0.8405 - val_loss: 0.0949 - val_accuracy: 0.9715
    Epoch 2/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.2164 - accuracy: 0.9070 - val_loss: 0.0763 - val_accuracy: 0.9740
    Epoch 3/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.2026 - accuracy: 0.9190 - val_loss: 0.0804 - val_accuracy: 0.9703
    Epoch 4/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1782 - accuracy: 0.9310 - val_loss: 0.0730 - val_accuracy: 0.9777
    Epoch 5/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.1799 - accuracy: 0.9305 - val_loss: 0.0735 - val_accuracy: 0.9777
    Epoch 6/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1644 - accuracy: 0.9280 - val_loss: 0.0758 - val_accuracy: 0.9777
    Epoch 7/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1804 - accuracy: 0.9265 - val_loss: 0.0771 - val_accuracy: 0.9740
    Epoch 8/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.1528 - accuracy: 0.9365 - val_loss: 0.0654 - val_accuracy: 0.9790
    Epoch 9/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.1635 - accuracy: 0.9375 - val_loss: 0.0639 - val_accuracy: 0.9765
    Epoch 10/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.1424 - accuracy: 0.9390 - val_loss: 0.0681 - val_accuracy: 0.9752
    Epoch 11/20
    63/63 [==============================] - 7s 107ms/step - loss: 0.1403 - accuracy: 0.9445 - val_loss: 0.0629 - val_accuracy: 0.9802
    Epoch 12/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.1313 - accuracy: 0.9460 - val_loss: 0.0753 - val_accuracy: 0.9728
    Epoch 13/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.1359 - accuracy: 0.9475 - val_loss: 0.0670 - val_accuracy: 0.9765
    Epoch 14/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.1455 - accuracy: 0.9420 - val_loss: 0.0794 - val_accuracy: 0.9666
    Epoch 15/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.1301 - accuracy: 0.9505 - val_loss: 0.0849 - val_accuracy: 0.9715
    Epoch 16/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.1444 - accuracy: 0.9445 - val_loss: 0.0769 - val_accuracy: 0.9678
    Epoch 17/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1261 - accuracy: 0.9500 - val_loss: 0.0741 - val_accuracy: 0.9728
    Epoch 18/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.1312 - accuracy: 0.9485 - val_loss: 0.0658 - val_accuracy: 0.9752
    Epoch 19/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.1387 - accuracy: 0.9405 - val_loss: 0.0760 - val_accuracy: 0.9715
    Epoch 20/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.1464 - accuracy: 0.9455 - val_loss: 0.0728 - val_accuracy: 0.9740


plot the validation accuracy and training accuracy:


```python
plt.plot(history4.history["accuracy"], label = "training")
plt.plot(history4.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")

plt.legend()
```




    <matplotlib.legend.Legend at 0x7f2a972f6690>




![Blog_Post_5_43_1.png](/images/Blog_Post_5_43_1.png)  
    


 A few observations here:
> **My validation accuracy becomes stabilized around 97% throughout the whole training process.** It is significantly higher than all the previous models we have trained and experimented by ourselves. We do not observe overfitting for our model 4. 

<br>

#### Step VI. Score on Test Data
Model 4, the model modified from a base model, is the clear winner. Let us take a look at how well the model will perform if we apply it to the unseen `test_dataset`:


```python
loss, accuracy = model4.evaluate(test_dataset)
```

    6/6 [==============================] - 2s 97ms/step - loss: 0.0700 - accuracy: 0.9740


> **For this exericise, we have achieved a 97.4% overall accuracy for the best model we have, which is significantly higher than the benchmark of 50% when we experimented with the dataset in the beginning.**

